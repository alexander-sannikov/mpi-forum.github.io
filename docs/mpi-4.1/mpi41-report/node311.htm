<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-one-side/one-side-2-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi4-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi41-report-html.idx -basedef mpi4defs.txt -o mpi41-report.tex mpi-report.tex 
-->
<title>Window That Allocates Shared Memory</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node311">13.2.3. Window That Allocates Shared Memory</span></h2>
<a href="node310.htm#Node310"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node308.htm#Node308"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node312.htm#Node312"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node308.htm#Node308"> Initialization</a>
<b>Next: </b><a href="node312.htm#Node312"> Window of Dynamically Attached Memory</a>
<b>Previous: </b><a href="node310.htm#Node310"> Window That Allocates Memory</a>
<p>
  
  
  
  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_WIN_ALLOCATE_SHARED(<span style="white-space:nowrap">size</span>, <span style="white-space:nowrap">disp_unit</span>, <span style="white-space:nowrap">info</span>, <span style="white-space:nowrap">comm</span>, <span style="white-space:nowrap">baseptr</span>, <span style="white-space:nowrap">win</span>)</TD></TR>  
<TR><TD> IN size</TD><TD>size of local window in bytes (non-negative integer)</TD></TR>  
<TR><TD> IN disp_unit</TD><TD>local unit size for displacements, in bytes (positive integer)</TD></TR>  
<TR><TD> IN info</TD><TD>info argument (handle)</TD></TR>  
<TR><TD> IN comm</TD><TD>intra-communicator (handle)</TD></TR>  
<TR><TD> OUT baseptr</TD><TD>address of local allocated window segment (choice)</TD></TR>  
<TR><TD> OUT win</TD><TD>window object (handle)</TD></TR>  
</TABLE>  
  <b> C binding</b><br>  <tt> int MPI_Win_allocate_shared(MPI_Aint size, int disp_unit, MPI_Info info, MPI_Comm comm, void *baseptr, MPI_Win *win) <br></tt>  
  
  <tt> int MPI_Win_allocate_shared_c(MPI_Aint size, MPI_Aint disp_unit, MPI_Info info, MPI_Comm comm, void *baseptr, MPI_Win *win) <br></tt>  
  <b> Fortran 2008 binding</b><br>  <tt> MPI_Win_allocate_shared(size, disp_unit, info, comm, baseptr, win, ierror) <br><br>USE, INTRINSIC :: ISO_C_BINDING, ONLY : C_PTR <br>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: <span style="white-space:nowrap">size</span> <br>INTEGER, INTENT(IN) :: <span style="white-space:nowrap">disp_unit</span> <br>TYPE(MPI_Info), INTENT(IN) :: <span style="white-space:nowrap">info</span> <br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span> <br>TYPE(C_PTR), INTENT(OUT) :: <span style="white-space:nowrap">baseptr</span> <br>TYPE(MPI_Win), INTENT(OUT) :: <span style="white-space:nowrap">win</span> <br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <tt> MPI_Win_allocate_shared(size, disp_unit, info, comm, baseptr, win, ierror) !(_c) <br><br>USE, INTRINSIC :: ISO_C_BINDING, ONLY : C_PTR <br>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: <span style="white-space:nowrap">size</span>, <span style="white-space:nowrap">disp_unit</span> <br>TYPE(MPI_Info), INTENT(IN) :: <span style="white-space:nowrap">info</span> <br>TYPE(MPI_Comm), INTENT(IN) :: <span style="white-space:nowrap">comm</span> <br>TYPE(C_PTR), INTENT(OUT) :: <span style="white-space:nowrap">baseptr</span> <br>TYPE(MPI_Win), INTENT(OUT) :: <span style="white-space:nowrap">win</span> <br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <b> Fortran binding</b><br>  <tt> MPI_WIN_ALLOCATE_SHARED(SIZE, DISP_UNIT, INFO, COMM, BASEPTR, WIN, IERROR) <br><br>INTEGER(KIND=MPI_ADDRESS_KIND) <span style="white-space:nowrap">SIZE</span>, <span style="white-space:nowrap">BASEPTR</span> <br>INTEGER <span style="white-space:nowrap">DISP_UNIT</span>, <span style="white-space:nowrap">INFO</span>, <span style="white-space:nowrap">COMM</span>, <span style="white-space:nowrap">WIN</span>, <span style="white-space:nowrap">IERROR</span> <br></tt>  
<P> 
<P> 
This procedure is collective over the group of  
<font face="sans-serif"> comm</font>. On each <font face="sans-serif"> MPI</font> process, it allocates memory of at least  
<font face="sans-serif"> size</font> bytes that is shared among all <font face="sans-serif"> MPI</font> processes in <font face="sans-serif"> comm</font>,  
and returns a pointer to  
the locally allocated segment in <font face="sans-serif"> baseptr</font> that can be used for  
load/store accesses on the calling <font face="sans-serif"> MPI</font> process. The locally allocated memory can be   
the target of load/store accesses by remote <font face="sans-serif"> MPI</font> processes; the base pointers for  
other <font face="sans-serif"> MPI</font> processes can be queried using the function  
<font face="sans-serif"> MPI_WIN_SHARED_QUERY</font>. The call also returns a handle to a new window that  
can be used by all <font face="sans-serif"> MPI</font> processes in <font face="sans-serif"> comm</font> to perform <font face="sans-serif"> RMA</font> operations. The  
size argument may be different at each <font face="sans-serif"> MPI</font> process and <font face="sans-serif"> size</font><font face="sans-serif">  = 0</font> is  
valid.  It is the user's responsibility to ensure that the communicator  
<font face="sans-serif"> comm</font> represents a group of <font face="sans-serif"> MPI</font> processes that are in the same  
<em> shared memory domain</em>, i.e., that they can create a  
<em> shared memory segment</em> that can be accessed by all processes in the group.  
The discussions of   
rationales for <font face="sans-serif"> MPI_ALLOC_MEM</font> and <font face="sans-serif"> MPI_FREE_MEM</font> in  
Section <a href="node251.htm#Node251">Memory Allocation</a> also apply to  
<font face="sans-serif"> MPI_WIN_ALLOCATE_SHARED</font>; in particular, see the rationale in  
Section <a href="node251.htm#Node251">Memory Allocation</a> for an explanation of the type used for  
<font face="sans-serif"> baseptr</font>. The allocated memory is <em> contiguous across processes in rank order</em>  
unless the info key <font face="sans-serif"> alloc_shared_noncontig</font> is  
specified. Contiguous across processes in rank order means that the first  
address in the memory segment of <font face="sans-serif"> MPI</font> process <i>i</i> is consecutive with the last  
address in the memory segment of <font face="sans-serif"> MPI</font> process <i>i-1</i>. This may enable the user to  
calculate remote address offsets with local information only.   
 <P> 
If the Fortran compiler provides <tt> TYPE(C_PTR)</tt>,   
then the following generic interface must be provided in the <tt>mpi</tt>  
module and should be provided in the (deprecated) <tt>mpif.h</tt> include file through overloading,   
i.e., with the same routine name as the  
routine with <font face="sans-serif"> INTEGER(KIND=MPI_ADDRESS_KIND)</font>  <tt>BASEPTR</tt>,   
but with a different specific procedure name:  
 <P> 
<br> 
<pre><tt>INTERFACE MPI_WIN_ALLOCATE_SHARED 
    SUBROUTINE MPI_WIN_ALLOCATE_SHARED(SIZE, DISP_UNIT, INFO, COMM, &amp; 
            BASEPTR, WIN, IERROR) 
        IMPORT :: MPI_ADDRESS_KIND 
        INTEGER :: DISP_UNIT, INFO, COMM, WIN, IERROR 
        INTEGER(KIND=MPI_ADDRESS_KIND) :: SIZE, BASEPTR 
    END SUBROUTINE 
    SUBROUTINE MPI_WIN_ALLOCATE_SHARED_CPTR(SIZE, DISP_UNIT, INFO, COMM, &amp; 
            BASEPTR, WIN, IERROR) 
        USE, INTRINSIC :: ISO_C_BINDING, ONLY : C_PTR 
        IMPORT :: MPI_ADDRESS_KIND 
        INTEGER :: DISP_UNIT, INFO, COMM, WIN, IERROR 
        INTEGER(KIND=MPI_ADDRESS_KIND) :: SIZE 
        TYPE(C_PTR) :: BASEPTR 
    END SUBROUTINE 
END INTERFACE 
</tt></pre> 
The base procedure name of this overloaded function is<font face="sans-serif"> MPI_WIN_ALLOCATE_SHARED_CPTR</font>. The implied specific procedure names  
are described in Section <a href="node469.htm#Node469">Interface Specifications, Procedure Names, and the Profiling Interface</a>.  
<P> 
The <font face="sans-serif"> info</font> argument can be used to specify hints  
similar to the <font face="sans-serif"> info</font> argument for <font face="sans-serif"> MPI_WIN_CREATE</font>,  
<font face="sans-serif"> MPI_WIN_ALLOCATE</font>, and <font face="sans-serif"> MPI_ALLOC_MEM</font>. The additional info  
key <font face="sans-serif"> alloc_shared_noncontig</font> allows the library to optimize the layout  
of the <em> shared memory segments</em> in memory.  
<P> 
 
<br> 
<em> Advice to users.</em>  
<P> 
If the info key <font face="sans-serif"> alloc_shared_noncontig</font> is not set to true, the  
allocation strategy is to allocate <em> contiguous memory</em> across <font face="sans-serif"> MPI</font> process  
ranks. This may limit the performance on some architectures because it  
does not allow the implementation to modify the data layout (e.g.,  
padding to reduce access latency).  
 (<em> End of advice to users.</em>) <br> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
If the user sets the info key <font face="sans-serif"> alloc_shared_noncontig</font> to true, the  
implementation can allocate the memory requested by each <font face="sans-serif"> MPI</font> process in a  
location that is close to this <font face="sans-serif"> MPI</font> process. This can be achieved by padding  
or allocating memory in special memory segments. Both techniques may  
make the address space across consecutive ranks <em> noncontiguous</em>.  
 (<em> End of advice to implementors.</em>) <br> 
  
For <em> contiguous shared memory</em> allocations, the default alignment requirements outlined  
for <font face="sans-serif"> MPI_ALLOC_MEM</font> in Section <a href="node251.htm#Node251">Memory Allocation</a> and the  
<font face="sans-serif"> mpi_minimum_memory_alignment</font> <font face="sans-serif"> info</font> key apply to the start  
of the <em> contiguous memory</em> that is returned in <font face="sans-serif"> baseptr</font> to the first <font face="sans-serif"> MPI</font> process  
with nonzero <font face="sans-serif"> size</font> argument. For noncontiguous memory allocations,  
the default alignment requirements and the <font face="sans-serif"> mpi_minimum_memory_alignment</font>  
<font face="sans-serif"> info</font> key apply to all <font face="sans-serif"> MPI</font> processes with nonzero <font face="sans-serif"> size</font> argument.  
<P> 
 
<br> 
<em> Advice to users.</em>  
<P> 
If the <font face="sans-serif"> info</font> key <font face="sans-serif"> alloc_shared_noncontig</font> is not set to true (or ignored by the <font face="sans-serif"> MPI</font>  
implementation), the alignment of the memory returned in <font face="sans-serif"> baseptr</font> to all but  
the first <font face="sans-serif"> MPI</font> process with nonzero <font face="sans-serif"> size</font> argument depends on the value of the <font face="sans-serif"> size</font> argument  
provided by other <font face="sans-serif"> MPI</font> processes.  
It is thus the user's responsibility to control the alignment of contiguous memory allocated for these <font face="sans-serif"> MPI</font> processes  
by ensuring that each <font face="sans-serif"> MPI</font> process provides a <font face="sans-serif"> size</font> argument that is an integral multiple of the alignment  
required for the application.  
 (<em> End of advice to users.</em>) <br> 
The consistency of load/store accesses from/to the shared memory as  
observed by the user program depends on the architecture.  
For details on how to create a consistent view see the description of <font face="sans-serif"> MPI_WIN_SHARED_QUERY</font>.  
<P> 
<TABLE><TR><TD COLSPAN=2>MPI_WIN_SHARED_QUERY(<span style="white-space:nowrap">win</span>, <span style="white-space:nowrap">rank</span>, <span style="white-space:nowrap">size</span>, <span style="white-space:nowrap">disp_unit</span>, <span style="white-space:nowrap">baseptr</span>)</TD></TR>  
<TR><TD> IN win</TD><TD>shared memory window (handle)</TD></TR>  
<TR><TD> IN rank</TD><TD>rank in the group of window win or <font face="sans-serif"> MPI_PROC_NULL</font> (non-negative integer)</TD></TR>  
<TR><TD> OUT size</TD><TD>size of the window segment (non-negative integer)</TD></TR>  
<TR><TD> OUT disp_unit</TD><TD>local unit size for displacements, in bytes (positive integer)</TD></TR>  
<TR><TD> OUT baseptr</TD><TD>address for load/store access to window segment (choice)</TD></TR>  
</TABLE>  
  <b> C binding</b><br>  <tt> int MPI_Win_shared_query(MPI_Win win, int rank, MPI_Aint *size, int *disp_unit, void *baseptr) <br></tt>  
  
  <tt> int MPI_Win_shared_query_c(MPI_Win win, int rank, MPI_Aint *size, MPI_Aint *disp_unit, void *baseptr) <br></tt>  
  <b> Fortran 2008 binding</b><br>  <tt> MPI_Win_shared_query(win, rank, size, disp_unit, baseptr, ierror) <br><br>USE, INTRINSIC :: ISO_C_BINDING, ONLY : C_PTR <br>TYPE(MPI_Win), INTENT(IN) :: <span style="white-space:nowrap">win</span> <br>INTEGER, INTENT(IN) :: <span style="white-space:nowrap">rank</span> <br>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(OUT) :: <span style="white-space:nowrap">size</span> <br>INTEGER, INTENT(OUT) :: <span style="white-space:nowrap">disp_unit</span> <br>TYPE(C_PTR), INTENT(OUT) :: <span style="white-space:nowrap">baseptr</span> <br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <tt> MPI_Win_shared_query(win, rank, size, disp_unit, baseptr, ierror) !(_c) <br><br>USE, INTRINSIC :: ISO_C_BINDING, ONLY : C_PTR <br>TYPE(MPI_Win), INTENT(IN) :: <span style="white-space:nowrap">win</span> <br>INTEGER, INTENT(IN) :: <span style="white-space:nowrap">rank</span> <br>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(OUT) :: <span style="white-space:nowrap">size</span>, <span style="white-space:nowrap">disp_unit</span> <br>TYPE(C_PTR), INTENT(OUT) :: <span style="white-space:nowrap">baseptr</span> <br>INTEGER, OPTIONAL, INTENT(OUT) :: <span style="white-space:nowrap">ierror</span> <br></tt>  
  <b> Fortran binding</b><br>  <tt> MPI_WIN_SHARED_QUERY(WIN, RANK, SIZE, DISP_UNIT, BASEPTR, IERROR) <br><br>INTEGER <span style="white-space:nowrap">WIN</span>, <span style="white-space:nowrap">RANK</span>, <span style="white-space:nowrap">DISP_UNIT</span>, <span style="white-space:nowrap">IERROR</span> <br>INTEGER(KIND=MPI_ADDRESS_KIND) <span style="white-space:nowrap">SIZE</span>, <span style="white-space:nowrap">BASEPTR</span> <br></tt>  
<P> 
This function queries the <font face="sans-serif"> MPI</font> process-local address for remote memory segments  
created with <font face="sans-serif"> MPI_WIN_ALLOCATE_SHARED</font>, <font face="sans-serif"> MPI_WIN_ALLOCATE</font>,  
and <font face="sans-serif"> MPI_WIN_CREATE</font>. This function can return different <font face="sans-serif"> MPI</font> process-local addresses  
for the same physical memory when called by different <font face="sans-serif"> MPI</font> processes. The returned memory can be used for  
load/store accesses subject to the constraints defined in Section <a href="node337.htm#Node337">Semantics and Correctness</a>.  
When <font face="sans-serif"> rank</font> is <font face="sans-serif"> MPI_PROC_NULL</font>, the <font face="sans-serif"> baseptr</font>, <font face="sans-serif"> disp_unit</font>, and <font face="sans-serif"> size</font>  
returned are the base, displacement unit, and size of the memory segment belonging to the <font face="sans-serif"> MPI</font> process with the lowest  
rank in the <em> shared memory domain</em> that specified <font face="sans-serif"> size</font><font face="sans-serif">  &gt; 0</font>. If all <font face="sans-serif"> MPI</font> processes in the group  
attached to the window specified <font face="sans-serif"> size</font><font face="sans-serif">  = 0</font>, then the call returns <font face="sans-serif"> size</font><font face="sans-serif">  = 0</font>  
and a <tt>baseptr</tt> as if <font face="sans-serif"> MPI_ALLOC_MEM</font> was called with <font face="sans-serif"> size</font><font face="sans-serif">  = 0</font>.  
<P> 
Only <font face="sans-serif"> MPI_WIN_ALLOCATE_SHARED</font> is guaranteed to allocate <em> shared memory</em>.  
Implementations are permitted, where possible, to provide <em> shared memory</em> for windows created with  
<font face="sans-serif"> MPI_WIN_CREATE</font> and <font face="sans-serif"> MPI_WIN_ALLOCATE</font>. However,  
availability of <em> shared memory</em> is not guaranteed.  
When the remote memory segment corresponding to a particular process cannot be accessed directly,  
this call returns <font face="sans-serif"> size</font><font face="sans-serif">  = 0</font> and a <font face="sans-serif"> baseptr</font> as if <font face="sans-serif"> MPI_ALLOC_MEM</font>  
was called with <font face="sans-serif"> size</font><font face="sans-serif">  = 0</font>.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
<font face="sans-serif"> MPI_WIN_SHARED_QUERY</font> may only be called on windows created by a call to  
<font face="sans-serif"> MPI_WIN_ALLOCATE_SHARED</font>, <font face="sans-serif"> MPI_WIN_ALLOCATE</font>,  
or <font face="sans-serif"> MPI_WIN_CREATE</font>. The potential for multiple memory regions in windows  
created through <font face="sans-serif"> MPI_WIN_CREATE_DYNAMIC</font> means that these windows  
cannot be used as input for <font face="sans-serif"> MPI_WIN_SHARED_QUERY</font>.  
 (<em> End of rationale.</em>) <br> 
 
<br> 
<em> Advice to users.</em>  
<P> 
For windows allocated using <font face="sans-serif"> MPI_WIN_ALLOCATE</font>  
or <font face="sans-serif"> MPI_WIN_CREATE</font>, the group of <font face="sans-serif"> MPI</font> processes for which the implementation may provide shared memory can be determined using <font face="sans-serif"> MPI_COMM_SPLIT_TYPE</font> described in Section <a href="node188.htm#Node188">Communicator Constructors</a>.  
 (<em> End of advice to users.</em>) <br> 
The consistency of load/store accesses from/to the <em> shared memory</em> as  
observed by the user program depends on the architecture. A consistent  
view can be created in the <em> unified memory model</em> (see   
Section <a href="node326.htm#Node326">Memory Model</a>) by utilizing the window  
synchronization functions (see Section <a href="node327.htm#Node327">Synchronization Calls</a>) or  
explicitly completing outstanding store accesses (e.g., by calling  
<font face="sans-serif"> MPI_WIN_FLUSH</font>). <font face="sans-serif"> MPI</font> does not define the semantics for accessing  
<em> shared window memory</em> in the <em> separate memory model</em>.  
<P> 
If the Fortran compiler provides <tt> TYPE(C_PTR)</tt>,   
then the following generic interface must be provided in the <tt>mpi</tt>  
module and should be provided in the (deprecated) <tt>mpif.h</tt> include file through overloading,   
i.e., with the same routine name as the  
routine with <font face="sans-serif"> INTEGER(KIND=MPI_ADDRESS_KIND)</font>  <tt>BASEPTR</tt>,   
but with a different specific procedure name:  
 <P> 
<br> 
<pre><tt>INTERFACE MPI_WIN_SHARED_QUERY 
    SUBROUTINE MPI_WIN_SHARED_QUERY(WIN, RANK, SIZE, DISP_UNIT, &amp; 
            BASEPTR, IERROR) 
        IMPORT :: MPI_ADDRESS_KIND 
        INTEGER :: WIN, RANK, DISP_UNIT, IERROR 
        INTEGER(KIND=MPI_ADDRESS_KIND) :: SIZE, BASEPTR 
    END SUBROUTINE 
    SUBROUTINE MPI_WIN_SHARED_QUERY_CPTR(WIN, RANK, SIZE, DISP_UNIT, &amp; 
            BASEPTR, IERROR) 
        USE, INTRINSIC :: ISO_C_BINDING, ONLY : C_PTR 
        IMPORT :: MPI_ADDRESS_KIND 
        INTEGER :: WIN, RANK, DISP_UNIT, IERROR 
        INTEGER(KIND=MPI_ADDRESS_KIND) :: SIZE 
        TYPE(C_PTR) :: BASEPTR 
    END SUBROUTINE 
END INTERFACE 
</tt></pre> 
The base procedure name of this overloaded function is  
<font face="sans-serif"> MPI_WIN_SHARED_QUERY_CPTR</font>. The implied specific  
procedure names  
are described in Section <a href="node469.htm#Node469">Interface Specifications, Procedure Names, and the Profiling Interface</a>.  
<P> 

<P>
<hr>
<a href="node310.htm#Node310"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node308.htm#Node308"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node312.htm#Node312"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node308.htm#Node308"> Initialization</a>
<b>Next: </b><a href="node312.htm#Node312"> Window of Dynamically Attached Memory</a>
<b>Previous: </b><a href="node310.htm#Node310"> Window That Allocates Memory</a>
<p>
<HR>
Return to <A HREF="node601.htm">MPI-4.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-4.1 of November 2, 2023<BR>
HTML Generated on November 19, 2023
</FONT>
</body>
</html>
