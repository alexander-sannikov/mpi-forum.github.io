<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-coll/coll-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi4-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi41-report-html.idx -basedef mpi4defs.txt -o mpi41-report.tex mpi-report.tex 
-->
<title>Applying Collective Operations to Inter-Communicators</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node117">7.2.2. Applying Collective Operations to Inter-Communicators</span></h2>
<a href="node116.htm#Node116"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node115.htm#Node115"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node118.htm#Node118"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node115.htm#Node115"> Communicator Argument</a>
<b>Next: </b><a href="node118.htm#Node118"> Specifics for Inter-Communicator Collective Operations</a>
<b>Previous: </b><a href="node116.htm#Node116"> Specifics for Intra-Communicator Collective Operations</a>
<p>
  
  
  
<P> 
To understand how collective operations apply to inter-communicators,  
we can view most <font face="sans-serif"> MPI</font> intra-communicator  
collective operations as fitting one of the following categories (see, for  
instance,   
[<a href="node600.htm#-Bib64">64</a>]):  
<dl> 
 
<dt> 
<b>All-To-All</b><dd> 
 All <font face="sans-serif"> MPI</font> processes contribute to the result.  All <font face="sans-serif"> MPI</font> processes  
  receive the result.    
  <ul> 
   
<li><font face="sans-serif"> MPI_ALLGATHER</font>, <font face="sans-serif"> MPI_IALLGATHER</font>, <font face="sans-serif"> MPI_ALLGATHER_INIT</font>,    
  <font face="sans-serif"> MPI_ALLGATHERV</font>, <font face="sans-serif"> MPI_IALLGATHERV</font>, <font face="sans-serif"> MPI_ALLGATHERV_INIT</font>  
   
<li><font face="sans-serif"> MPI_ALLTOALL</font>, <font face="sans-serif"> MPI_IALLTOALL</font>, <font face="sans-serif"> MPI_ALLTOALL_INIT</font>,  
  <font face="sans-serif"> MPI_ALLTOALLV</font>, <font face="sans-serif"> MPI_IALLTOALLV</font>, <font face="sans-serif"> MPI_ALLTOALLV_INIT</font>,  
  <font face="sans-serif"> MPI_ALLTOALLW</font>, <font face="sans-serif"> MPI_IALLTOALLW</font>, <font face="sans-serif"> MPI_ALLTOALLW_INIT</font>  
   
<li><font face="sans-serif"> MPI_ALLREDUCE</font>, <font face="sans-serif"> MPI_IALLREDUCE</font>, <font face="sans-serif"> MPI_ALLREDUCE_INIT</font>,    
  <font face="sans-serif"> MPI_REDUCE_SCATTER_BLOCK</font>, <font face="sans-serif"> MPI_IREDUCE_SCATTER_BLOCK</font>,   
  <font face="sans-serif"> MPI_REDUCE_SCATTER_BLOCK_INIT</font>,   
  <font face="sans-serif"> MPI_REDUCE_SCATTER</font>,   <font face="sans-serif"> MPI_IREDUCE_SCATTER</font>,   
  <font face="sans-serif"> MPI_REDUCE_SCATTER_INIT</font>  
   
<li><font face="sans-serif"> MPI_BARRIER</font>, <font face="sans-serif"> MPI_IBARRIER</font>, <font face="sans-serif"> MPI_BARRIER_INIT</font>   
  </ul> 
<br> 
 
<dt> 
<b>All-To-One</b><dd> 
 All <font face="sans-serif"> MPI</font> processes contribute to the result.  One <font face="sans-serif"> MPI</font> process  
  receives the result.  
  <ul> 
   
<li><font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_IGATHER</font>, <font face="sans-serif"> MPI_GATHER_INIT</font>,   
  <font face="sans-serif"> MPI_GATHERV</font>, <font face="sans-serif"> MPI_IGATHERV</font>, <font face="sans-serif"> MPI_GATHERV_INIT</font>  
   
<li><font face="sans-serif"> MPI_REDUCE</font>, <font face="sans-serif"> MPI_IREDUCE</font>, <font face="sans-serif"> MPI_REDUCE_INIT</font>,  
  </ul> 
<br> 
 
<dt> 
<b>One-To-All</b><dd> 
 One <font face="sans-serif"> MPI</font> process contributes to the result.  All <font face="sans-serif"> MPI</font> processes  
  receive the result.  
  <ul> 
   
<li><font face="sans-serif"> MPI_BCAST</font>, <font face="sans-serif"> MPI_IBCAST</font>, <font face="sans-serif"> MPI_BCAST_INIT</font>  
   
<li><font face="sans-serif"> MPI_SCATTER</font>, <font face="sans-serif"> MPI_ISCATTER</font>, <font face="sans-serif"> MPI_SCATTER_INIT</font>,    
  <font face="sans-serif"> MPI_SCATTERV</font>, <font face="sans-serif"> MPI_ISCATTERV</font>, <font face="sans-serif"> MPI_SCATTERV_INIT</font>  
  </ul> 
<br> 
 
<dt> 
<b>Other:</b><dd> 
 Collective operations that do not fit into one of the above  
  categories.  
  <ul> 
   
<li><font face="sans-serif"> MPI_SCAN</font>, <font face="sans-serif"> MPI_ISCAN</font>, <font face="sans-serif"> MPI_SCAN_INIT</font>   
  <font face="sans-serif"> MPI_EXSCAN</font>, <font face="sans-serif"> MPI_IEXSCAN</font>, <font face="sans-serif"> MPI_EXSCAN_INIT</font>  
  </ul> 
<br> 
</dl> 
<br> 
The data movement patterns of <font face="sans-serif"> MPI_SCAN</font>, <font face="sans-serif"> MPI_ISCAN</font>,   
<font face="sans-serif"> MPI_SCAN_INIT</font>, <font face="sans-serif"> MPI_EXSCAN</font>, <font face="sans-serif"> MPI_IEXSCAN</font> and <font face="sans-serif"> MPI_EXSCAN_INIT</font>  
do not fit this taxonomy.  
<P> 
<P> 
The application of collective communication to  
inter-communicators is best described in terms of two groups.  
For example, an all-to-all  
<font face="sans-serif"> MPI_ALLGATHER</font> operation can be described as collecting data  
from all members of one group with the result appearing in all members  
of the other group (see Figure <a href="node117.htm#Figure5">5</a>).  As another  
example, a one-to-all <font face="sans-serif"> MPI_BCAST</font> operation sends data from one  
member of one group to all members of the other group.  
Collective computation operations such as <font face="sans-serif"> MPI_REDUCE_SCATTER</font> have  
a   
similar interpretation (see Figure <a href="node117.htm#Figure6">6</a>).  
For intra-communicators, these two groups  
are the same.  For inter-communicators, these two groups are distinct.  
For the all-to-all operations, each such operation is described in two phases,  
so that it   
has a symmetric, full-duplex behavior.  
<P> 
The following collective operations also apply to inter-communicators:  
<ul> 
 
<li><font face="sans-serif"> MPI_BARRIER</font>, <font face="sans-serif"> MPI_IBARRIER</font>, <font face="sans-serif"> MPI_BARRIER_INIT</font>,  
 
<li><font face="sans-serif"> MPI_BCAST</font>, <font face="sans-serif"> MPI_IBCAST</font>, <font face="sans-serif"> MPI_BCAST_INIT</font>,  
 
<li><font face="sans-serif"> MPI_GATHER</font>, <font face="sans-serif"> MPI_IGATHER</font>, <font face="sans-serif"> MPI_GATHER_INIT</font>,   
      <font face="sans-serif"> MPI_GATHERV</font>, <font face="sans-serif"> MPI_IGATHERV</font>, <font face="sans-serif"> MPI_GATHERV_INIT</font>,  
 
<li><font face="sans-serif"> MPI_SCATTER</font>, <font face="sans-serif"> MPI_ISCATTER</font>, <font face="sans-serif"> MPI_SCATTER_INIT</font>,  
      <font face="sans-serif"> MPI_SCATTERV</font>, <font face="sans-serif"> MPI_ISCATTERV</font>, <font face="sans-serif"> MPI_SCATTERV_INIT</font>,  
 
<li><font face="sans-serif"> MPI_ALLGATHER</font>, <font face="sans-serif"> MPI_IALLGATHER</font>, <font face="sans-serif"> MPI_ALLGATHER_INIT</font>,  
      <font face="sans-serif"> MPI_ALLGATHERV</font>, <font face="sans-serif"> MPI_IALLGATHERV</font>, <font face="sans-serif"> MPI_ALLGATHERV_INIT</font>,  
 
<li><font face="sans-serif"> MPI_ALLTOALL</font>, <font face="sans-serif"> MPI_IALLTOALL</font>, <font face="sans-serif"> MPI_ALLTOALL_INIT</font>,  
      <font face="sans-serif"> MPI_ALLTOALLV</font>, <font face="sans-serif"> MPI_IALLTOALLV</font>, <font face="sans-serif"> MPI_ALLTOALLV_INIT</font>,  
      <font face="sans-serif"> MPI_ALLTOALLW</font>, <font face="sans-serif"> MPI_IALLTOALLW</font>, <font face="sans-serif"> MPI_ALLTOALLW_INIT</font>,  
 
<li><font face="sans-serif"> MPI_ALLREDUCE</font>, <font face="sans-serif"> MPI_IALLREDUCE</font>, <font face="sans-serif"> MPI_ALLREDUCE_INIT</font>,  
      <font face="sans-serif"> MPI_REDUCE</font>, <font face="sans-serif"> MPI_IREDUCE</font>, <font face="sans-serif"> MPI_REDUCE_INIT</font>,  
 
<li><font face="sans-serif"> MPI_REDUCE_SCATTER_BLOCK</font>, <font face="sans-serif"> MPI_IREDUCE_SCATTER_BLOCK</font>,   
<font face="sans-serif"> MPI_REDUCE_SCATTER_BLOCK_INIT</font>, <font face="sans-serif"> MPI_REDUCE_SCATTER</font>,  
<font face="sans-serif"> MPI_IREDUCE_SCATTER</font>, <font face="sans-serif"> MPI_REDUCE_SCATTER_INIT</font>.  
</ul> 
<br> 
  <div style="text-align:center"><P><img width=1170 height=1620 src="collective-allgather.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 5: </b><span id="Figure5">Inter-communicator allgather.  The focus of data to one <font face="sans-serif"> MPI</font> process is 
    represented, not mandated by the semantics.  
    The two phases do allgathers in both directions.</span><P> 
  
    
  <div style="text-align:center"><P><img width=1068 height=831 src="collective-reduce_scatter.gif" alt="Image file"><P>
</div>  
  <br> 
<b>Figure 6: </b><span id="Figure6">Inter-communicator reduce-scatter.  The focus of data to one <font face="sans-serif"> MPI</font> process 
    is represented, not mandated by the semantics. 
    The two phases do reduce-scatters in both directions.</span><P> 
  
    

<P>
<hr>
<a href="node116.htm#Node116"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node115.htm#Node115"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node118.htm#Node118"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node115.htm#Node115"> Communicator Argument</a>
<b>Next: </b><a href="node118.htm#Node118"> Specifics for Inter-Communicator Collective Operations</a>
<b>Previous: </b><a href="node116.htm#Node116"> Specifics for Intra-Communicator Collective Operations</a>
<p>
<HR>
Return to <A HREF="node601.htm">MPI-4.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-4.1 of November 2, 2023<BR>
HTML Generated on November 19, 2023
</FONT>
</body>
</html>
